[{"id":"1f19f622d6850c416c86c516f221243f","title":"Nginx基础操作","content":"#快速启动一个Nginx\ndocker run --name nginx-learn -p 80:80 -d nginx\n1.常用命令#常用命令\n-T: 查看当前nginx的配置\n-s: 向master进程发送指令: \n    stop: 关闭\n    quit: 当前工作处理完成后关闭\n    reopen: 重启\n    reload: 重载配置文件，热重启\n2.语法\n每条指令以 ; 结尾，指令与参数之间以空格区隔\n指令块放在 {} 中\ninclude 允许引用外部的配置文件\n使用 # 符号添加注释\n使用 $ 符号使用变量\n部分指令的参数支持正则表达式\n\n3.全局变量#请求信息中的 Host，如果请求中没有 Host 行，则等于设置的服务器名，不包含端口\n$host\n#客户端请求类型，如 GET、POST\n$request_method\n#客户端的 IP 地址\n$remote_addr\n#请求中的参数\n$args\n#请求中变量名 PARAMETER 参数的值\n$arg_PARAMETERGET\n#请求头中的 Content-length 字段\n$content_length\n#客户端agent信息\n$http_user_agent\n#客户端cookie信息\n$http_cookie\n#客户端的IP地址\n$remote_addr\n#客户端的端口\n$remote_port\n#客户端agent信息\n$http_user_agent\n#请求使用的协议，如 HTTP&#x2F;1.0、HTTP&#x2F;1.1\n$server_protocol\n#服务器地址\n$server_addr\n#服务器名称\n$server_name\n#服务器的端口号\n$server_port\n#方法（如http，https）\n$schemeHTTP \n4.配置文件nginx.conf示例：\n#全局块，此处配置全局生效\ndaemon on;\nuser nobody;\nwork_process 2;\npid logs&#x2F;nginx.pid;\nerror_log logs&#x2F;error.log debug;\n#events块\nevents &#123;\n    #此处是处理连接的配置\n    #此处配置影响性能\n    worker_connections 1024;\n&#125;\n#http块\nhttp &#123;\n    # 最常用部分，代理、缓存、日志等配置  \n    include test.conf;\n    keepalive_timeout &#x3D; 10;\n    #server块\n    server &#123;\n        # 监听端口\n        listen 80\n        # 域名配置\n        server_name localhost\n        #location块\n        location &#x2F;one &#123;\n            # 配置请求路径是&#39;&#x2F;one&#39;的代理\n        &#125;\n        #同一个server块下可以有多个location块\n        location &#x2F;two &#123;\n            # 配置请求路径是&#39;&#x2F;two&#39;的代理\n        &#125;\n    &#125; \n    #同一个http块下可以有多个server块\n    server &#123;\n        # 配置另一个服务的代理\n    &#125;\n&#125;\n4-1.全局块一般位于events块之前，通常配置内容包括：\ndaemon#以守护模式运行Nginx\ndaemon on;\nuser#Nginx的用户\n#用法\nuser [用户名] [用户组]\n#示例: 允许root组的admin用户访问\nuser admin root\n## user在Windows中不生效\nuser nobody 或者 # user xx 代表所有用户都可以运行\nwork_process#配置工作线程数，一般与服务器的CPU核数保持一致\n#用法\nworker_process [线程数] | auto\n#示例: 指定2个线程\nworker_process 2;\npid#Nginx 主进程Pid的记录位置\n#用法\npid [路径]\n#示例\npid logs&#x2F;nginx.pid\nerror_log#日志保存路径\n#用法\nerror_log [路径] [日志级别,常用的级别：debug|info|error|warn]\n#示例\nerror_log logs&#x2F;error.log error\nerror_log logs&#x2F;info.log info\n#引入的配置文件\n4-2.events块worker_connections#配置单个worker的最大连接数\nworker_connections 2000;\n工作模式use epoll|select|poll|kqueue...\n\n4-3.http块client_max_body_size\nkeepalive_timeout\n负载均衡动静分离高可用最佳实践参考使用注意1.路径配置# 例子1\nserver &#123;\n    listen 8080;\n    server_name 192.168.0.222;\n    \n    location &#x2F;api &#123;\n                proxy_pass   http:&#x2F;&#x2F;192.168.1.123:9000;  \n            &#125;\n        \n# 例子2\nserver &#123;\n    listen 8080;\n    server_name 192.168.2.222;\n    \n    location &#x2F;api &#123;\n                proxy_pass   http:&#x2F;&#x2F;192.168.1.123:9000&#x2F;;  \n            &#125;\n注意location后面路径的 / 和proxy_pass路径的 /\n#例子1：\n#请求：\nhttp:&#x2F;&#x2F;192.168.0.222:8080&#x2F;api&#x2F;user&#x2F;login\n#nginx处理后的请求：\nhttp:&#x2F;&#x2F;192.168.1.123:9000&#x2F;api&#x2F;user&#x2F;login\n#例子2：\n#请求：\nhttp:&#x2F;&#x2F;192.168.0.222:8080&#x2F;api&#x2F;user&#x2F;login\n#nginx处理后的请求：\nhttp:&#x2F;&#x2F;192.168.1.123:9000&#x2F;&#x2F;user&#x2F;login\n例子1与例子2的区别是例子2中的proxy_pass除了IP和Port外，还配置了上下文，这里的规则是：1、如果proxy_pass中的路径存在上下文(即端口后存在/)：\n\n替换IP和Port；\n将location中的路径替换为上下文；\n拼接余下的路径；\n\n2、如果proxy_pass中的路径不存在上下文(即端口后没有/及后续路径)：\n\n替换IP和Port，其余不动；\n\n","slug":"Nginx基础操作","date":"2022-01-28T08:38:57.000Z","categories_index":"Nginx","tags_index":"Nginx,工具","author_index":"Shepard"},{"id":"27744e614f7ee333f0c3a9e11c89d431","title":"日常Linux操作总结","content":"常用场景包括：\n\n1、查看Linux的版本、cpu、内存、磁盘等信息\n2、查看磁盘占用，查找文件和目录，处理大文件\n3、处理日志\n4、端口、进程相关操作\n5、crontab定时任务\n6、自定义快捷命令\n7、常见环境配置：防火墙、免登陆、yum、时间、JDK等\n\n1.查看基础信息# 查看CentOS系统版本号\ncat &#x2F;etc&#x2F;centos-release\n# 查看系统内核\nuname -r\n# 查看系统位数\ngetconf LONG_BIT\n# 查看cpu和内存，磁盘等信息\n\n2.处理磁盘、大文件2-1.使用的命令find命令查找目录和文件# 常用参数：\n-type: 文件类型，d 目录 f 文件\n-name: 名称 通配符：&quot;*.*&quot; 文件名称:文件后缀\n-iname: 名称不区分大小写\n-size: 文件&#x2F;目录大小\n# 执行参数：\n-exec： find的结果作为exec的入参\n-ok：功能同-exec，区别是在请求之前询问是否执行，输入y执行\n# 查询所有目录下所有大于50M的文件\nfind &#x2F; -size +50M -exec ls -lh &#123;&#125; \\;\n# 查找所有目录下jmx类型的文件\nfind &#x2F; -type f -name &quot;*.jmx&quot; -exec ls -lh &#123;&#125; \\;\n# 查找指定目录下文件名为test的文件，不区分大小写\nfind &#x2F;&#123;dir&#125; -type f -iname &quot;test&quot; -exec ls -lh &#123;&#125; \\;\n# 查找指定目录下不为test的文件\nfind &#x2F;&#123;dir&#125; -type f !-name &quot;test&quot; -exec ls -lh &#123;&#125; \\;\n与正则配合使用#\n\n\ndu命令查看目录和文件的磁盘使用空间# 常用参数：\n-k: 以KB单位显示\n-m: 以MB单位显示\n-h: 以K M G为单位显示，提高可读性\n--max-depth: 显示层级\n# 查看&#x2F;opt目录下的目录和文件大小并按文件从大到小排序\ndu -h --max-depth&#x3D;1 &#x2F;opt&#x2F; | sort\ndf命令查看磁盘中的可用空间# 常用参数\n-a: 查看所有文件系统的磁盘占用，单位默认KB\n-h: 以K M G为单位显示，注意：这里的1k&#x3D;1000byte,1m&#x3D;1000k\nsort排序#常用参数：\n-u: 排序后去除重复行\n-n: 按照数值排序\n-r: 按降序排序，sort默认升序排序\n-t: 指定分隔符\n-k: 指定列数，与-t配合使用\n#当前目录下的文件按照文件大小排序\nls -lh | sort -n -k 5\nuniq去重#常用参数\n-c: 去重并在第一列显示每一行重复的次数\n\n2-2.场景1、当前磁盘满了，需要定位大文件并删除#1、查看自盘占用\ndf -h\n#2、进入磁盘占用大的目录找到大文件\ndu -h --max-depth&#x3D;1 &#x2F;opt&#x2F; | sort\n2、找到/test目录下所有大于1G的.log文件删除find &#x2F;test -name &quot;*.log&quot; -size +1024M -exec rm -rf &#123;&#125; \\;\n\n3.处理日志包括：\n\n1、日志内容筛选与编辑;正则匹配，命令行高亮显示\n2、日志文件切割与批处理\n\n使用到的命令：split cat grep awk sed\n3-1.使用的命令split命令切割文件#用法\nsplit [-b ][-C ][-][-l ][要切割的文件][输出文件名前缀][-a ]\n#常用参数：\n-b: 指定拆分文件大小，也可以指定 K、M、G、T 等单位\n-l: 指定每多少行要拆分成一个文件\n-d: 使用数字作为拆分文件的后缀\n-a: 指定后缀长度\n# 将test.log拆分成每个文件大小不超过1M，且命名采用test_01,test_02...的文件\nsplit -b 1M -d test.log test_\n# 将test.log拆分成每个文件不超过100行，且命名采用test_01,test_02...的文件\nsplit -l 100 -d test.log test_\ntail命令分析日志文件#常用参数：\n-f: 当文件增长时，持续输出\n-n: 输出文件最后n行，而不是默认的最后10行\n--pid: 与-f结合使用，在PID终止后结束 --\n-q: 不输出文件名\n-s: 与-f结合使用，-s&#x3D;n：每次输出间隔n秒\n-v: 输出文件名\n# 输出test.log\ntail -f test.log\n# 输出test.log和error.log\ntail -f test.log error.log\n# 输出test.log中最后200行的内容\ntail -n 200 test.log\n与head、grep、正则的配合使用#head常用参数\n-n: 显示起始的n行，非默认的10行\n-v: 显示文件名\n-q: 不显示文件名\n#grep常用参数\n-v: 不包含匹配的所有行\n-c: 计算符合匹配的列数\n-w: 只显示完整匹配的结果，不包括部分匹配，比如匹配要求是apple，则只有准确地为apple的内容会返回\n-e: 后面接正则条件，一个参数只能加一个条件\n-E: 后面接正则条件，一个参数可以加多个条件\n-i: 忽略大小写\n-o: 只显示匹配pattern的部分\n-n: 输出内容时添加结果所在的行号\n-r: 递归匹配\n-color: -color&#x3D;auto &#x2F; always &#x2F; never;\n#a,b的意义分别表示加颜色的方式和颜色值\nexport GREP_COLOR&#x3D;&#39;a;b&#39;\n#a取值范围:【0,1,4,5,7,8】 0关闭所有属性; 1设置高亮度; 4下划线; 5闪烁; 7反显; 8消隐; \n#b取值范围:【30-37或40-47】30 black 31 red 32 green 33 yellow 34 blue 35 purple 36 cyan 37 white 30—37 设置前景色 40—47 设置背景色\n-A: 打印出紧随匹配的行之后的下文 NUM 行\n-B: 打印出匹配的行之前的上文 NUM 行\n-C: 打印出匹配的行的上下文前后各 NUM 行\n\n#pattern的常用参数\n\n# 输出test.log的第100行到第200行\ncat test.log | head -n 200 | tail -n 100\n# 持续输出test.log中包含”Listener“的行\ntail -f jmeter.log | grep &quot;Listener&quot;\n\nawk处理列数据#用法 pattern：匹配内容；action：找到匹配后对每一行执行的操作\nawk &#39;&#123;pattern + action&#125;&#39; &#123;filenames&#125;\n#内置变量：\n$0: 整行\n$1~n: 第n列\nNF: 字段数量\nNR: 行数\nFS: -F 分隔字段符号，可以传一个或多个\nBEGIN和END模块\n#输出test.log的第100行到第200行使用awk实现\nawk &#39;&#123;if(NR&gt;100 &amp;&amp; NR&lt;200)print $0 &#125;&#39; test.log\n#输出test.log中带有https的行中第二列是200的内容\ncat test.log | grep -w &#39;https&#39; | awk &#39;&#123;if ($2 &#x3D;&#x3D; 200)print&#125;&#39;\n#统计test.log中带有https的行中第二列是200的数量\n## 注意在加入BEGIN和END语句之后，不要忘记分号\ncat test.log | grep -w &#39;https&#39; | awk &#39;&#123;count++;if ($2 &#x3D;&#x3D; 200);&#125; END&#123;print &quot;total 200 is&quot;,count&#125;&#39;\n# \n\nsed处理行数据、替换数据#常用参数：\n\n\n3-2.场景1、匹配输出test.log中带有https的行并高亮显示# 这里grep使用-w参数为了过滤带有http的行，只匹配完全是https的行\ntail -f test.log | grep -w &quot;https&quot; --color&#x3D;auto\n2、统计Nginx日志中访问量前10的IP# 注意参数-n，不使用-n参数会得到错误的结果\n\nawk &#39;&#123;a[$1]++&#125; END&#123;for(i in a)print i,a[i]&#125;&#39; access.log | sort -n -r -k 2 | head -10 \n3、统计Nginx日志中访问超过10次的IPawk &#39;&#123;a[$1]++&#125; END&#123;for(i in a)&#123;if(a[i]&gt;10)print i,a[i]&#125;&#125;&#39; access.log | sort -nr -k 2 \n4、统计每个IP访问结果状态码的数量#方法一，使用awk统计\nawk &#39;&#123;a[$1&quot; &quot;$13]++&#125;END&#123;for(i in a)print i,a[i]&#125;&#39; access.log | sort -r\n#方法二，使用uniq做去重和统计\nawk &#39;&#123;print $1 &quot; &quot;$13&#125;&#39; access.log | sort -r | uniq -c\n4.端口、进程操作5.crontab定时任务6.自定义快捷命令编写shell函数的sh文件，将路径放在当前shell的环境变量下，即可在命令行中通过命令的形式调用函数\n7.其他常规操作","slug":"日常Linux使用总结","date":"2022-01-27T07:58:57.000Z","categories_index":"Linux","tags_index":"Linux,Shell","author_index":"Shepard"},{"id":"94eac58137c582610fa66d5e01c061b5","title":"Git基础操作","content":"","slug":"Git基础操作","date":"2022-01-27T07:58:57.000Z","categories_index":"Git","tags_index":"分支管理,版本管理","author_index":"Shepard"},{"id":"6026292b9a114dd7e9230f64f6ee9341","title":"测试中的Python多线程实践","content":"","slug":"测试中的Python多线程实践","date":"2022-01-26T08:36:49.000Z","categories_index":"Python","tags_index":"多线程","author_index":"Shepard"},{"id":"6bc094001a2fbe33ccfd1d00db4b8e67","title":"Docker总结（四）trouble shooting","content":"","slug":"Docker总结（四）Trouble Shooting","date":"2022-01-26T07:10:35.000Z","categories_index":"Docker","tags_index":"docker","author_index":"Shepard"},{"id":"886fb97c6a9f1093795d1bc241df7452","title":"Kubernetes（二）搭建K8s集群","content":"","slug":"Kubernetes（二）搭建K8s集群","date":"2022-01-26T07:10:35.000Z","categories_index":"Kubernetes","tags_index":"docker","author_index":"Shepard"},{"id":"b5d58b1fda75e2f048e5df658e921d2f","title":"Docker总结（三）storage driver","content":"","slug":"Docker总结（三）storage driver","date":"2022-01-26T07:07:35.000Z","categories_index":"Docker","tags_index":"docker","author_index":"Shepard"},{"id":"a15ee2548be8ea6598d20f063912efe1","title":"Docker总结（二）Docker网络","content":"","slug":"Docker总结（二）Docker网络","date":"2022-01-26T07:04:35.000Z","categories_index":"Docker","tags_index":"Docker网络","author_index":"Shepard"},{"id":"d4b6875f4e07d945b6294d6c595242e6","title":"Docker（一）Docker基础","content":"","slug":"Docker总结（一）Docker基础","date":"2022-01-26T07:02:35.000Z","categories_index":"Docker","tags_index":"Docker基础","author_index":"Shepard"},{"id":"d601d92e2a559886548c50e7674328c4","title":"Python中的面向对象","content":"","slug":"Python中的面向对象","date":"2022-01-26T04:11:25.000Z","categories_index":"Python","tags_index":"python语法","author_index":"Shepard"},{"id":"dc8d6cc63bf744f7dcebfa2de74e1b03","title":"UI自动化的打开方式","content":"\n","slug":"UI自动化的打开方式","date":"2022-01-26T04:11:25.000Z","categories_index":"测试开发","tags_index":"自动化,UI自动化","author_index":"Shepard"},{"id":"a30b755161583e241de805e3dc010577","title":"基于jacoco的测试覆盖度","content":"","slug":"基于jacoco的测试覆盖度","date":"2022-01-26T04:11:25.000Z","categories_index":"jacoco","tags_index":"java,覆盖度,精准测试","author_index":"Shepard"},{"id":"222d17415b9ab8db6d4794150d1086bf","title":"测试框架中的设计模式实践","content":"","slug":"测试框架中的设计模式实践","date":"2022-01-26T04:11:25.000Z","categories_index":"设计模式","tags_index":"设计模式","author_index":"Shepard"},{"id":"115931d60223732fb6d5e1e1eb7110e3","title":"Kubernetess（一）K8s与Docker简介","content":"","slug":"K8s（一）K8s与Docker简介","date":"2022-01-25T08:40:35.000Z","categories_index":"持续集成","tags_index":"环境治理","author_index":"Shepard"},{"id":"c198982027fbd7f7058f99b8a41a9c18","title":"Python的内存机制","content":"","slug":"Python的内存机制","date":"2022-01-25T08:40:35.000Z","categories_index":"Python","tags_index":"python语法","author_index":"Shepard"},{"id":"fe7a1f29f308686faf2c7367fba7f77e","title":"性能需求分析与评估","content":"","slug":"性能需求分析与评估","date":"2022-01-25T08:40:35.000Z","categories_index":"性能","tags_index":"需求分析,测试分析","author_index":"Shepard"},{"id":"d4b768a04b252f8943cc40ff24e9a3ba","title":"测试需求分析","content":"测试分析思路：首先梳理出主干流程-&gt;然后梳理流程中所有可能的路径\n1、首先梳理出主干流程主谓宾\n2、然后梳理流程中所有可能的路径关注的点：\n2-1、对于状态流转：不同角色\n不同操作\n不同状态变化规则\n是否按照以上三点进行拆分，比如不同的角色是否会影响规则，如果有影响，则拆分为多个流程\n2-2、对于流程的起点，终点，节点：数据从哪里来，到哪里去，节点如何处理输入的数据（这里不是指技术上的处理，指的是业务上的）\n是否依赖第三方\n各个节点/依赖方的状态变化时，规则如何处理\n2-3、从用户、业务的角度思考用户角度：\n行为的合理性\n易用性\n页面布局 配色\n业务角度：\n流程的合理性、流畅性、完整性（流程有没有闭环，有没有缺失的场景）\n2-4、非功能性需求安全\n性能\n","slug":"测试需求分析","date":"2022-01-25T08:34:37.000Z","categories_index":"软件测试","tags_index":"需求分析,测试分析","author_index":"Shepard"},{"id":"7c96820221324ccf244ace14cfe9ee43","title":"JMeter源码分析（三）JMeter的多线程模式","content":"","slug":"JMeter源码分析（三）JMeter的多线程模式","date":"2022-01-25T08:23:53.000Z","categories_index":"性能","tags_index":"JMeter,源码","author_index":"Shepard"},{"id":"c8391535c2748168c796926b77908e3d","title":"JMeter源码分析（二）JMeter的协议和Sampler","content":"JMeter源码分析（二）JMeter的协议和Sampler","slug":"JMeter源码分析（二）JMeter的协议和Sampler","date":"2022-01-25T08:22:53.000Z","categories_index":"性能","tags_index":"JMeter,源码","author_index":"Shepard"},{"id":"d1c22133881201ef28276da04c4f4520","title":"JMeter源码分析（一）JMeter的架构","content":"","slug":"JMeter源码分析（一）JMeter的架构","date":"2022-01-25T04:33:57.000Z","categories_index":"性能","tags_index":"JMeter,源码","author_index":"Shepard"},{"id":"118f149cd8b46dd25f6defc2189d56a1","title":"Linux监控指标","content":"Linux监控指标\n工具使用1、lscpu","slug":"Linux监控指标","date":"2022-01-25T04:33:57.000Z","categories_index":"Linux","tags_index":"Linux","author_index":"Shepard"},{"id":"224bc71bb6fcb80309744682916f3702","title":"接口测试（一）聊聊接口测试","content":"接口测试是个讨论度和普及度很高的话题了，只要身处这个行业，无论了解到什么程度，都能聊几句接口测试。不过即便如此，接口作为面向对象领域的重要实现，仍然有举足轻重的地位，本系列的第一个话题打算从接口开始。\n\n首先从看过无数次的Test Pyramid开始\n  \n 从下至上，测试粒度越来越粗，关联的服务越来越多，链路越来越长，定位问题耗时越来越多，发现问题修改的成本越来越高\n 对于国内中小企业的测试人员来说，接口测试是性价比最高的选择，单元测试虽然理论上发现问题的成本更低，但是相对地对开发人员的负担也会升高，以Java为例，常用的单元测试框架JUnit实现的测试代码与业务代码的比例接近3：1，在业务重，开发资源紧张的时候推进单元测试，显然不合适，而且想要单元测试的效果达到预期，要具备几个前提条件：\n首先，目标要清晰\n不少人认为单元测试无用的依据是，和后面的功能测试、接口测试重复，没有价值；这就要回到了测试金字塔了，尽管接口的粒度相比集成测试已经细了一些，但是\n其次，测试用例的设计要过关\n测试人员需要写出合格的测试用例（分支覆盖度足够，可读性强）并提供给开发作为单元测试用例的依据，这样开发才能够快速写出足够覆盖度的单元测试case；\n最后，想办法降低编写单元测试的成本\n不影响业务进度的同时，减少开发人员的抵触心理；\n测试开发可以调研一些效率更高的单元测试框架，或者开发一些效率工具供开发使用，降低编写成本；同时搭建和维护代码覆盖率的环境供开发使用，这也是测试左移的一部分\n当然这个还是要看实际情况，如果开发已经在持续加班做业务了，想推单元测试就变得很困难\n 尽管敏捷测试、精准测试逐渐兴起，上面的经典模型仍然能够给大多数测试行为提供参考。常见流程下的测试活动大体可以分为以下几种：\n\n 接口测试涵盖服务测试中的单接口测试和端到端中的接口流程测试，功能、性能、安全测试三者都不同程度穿插着对接口的测试。\n接口测试怎么做从用例设计、数据管理、框架三个方面来看看接口测试是怎么搞的\n1、用例设计2、数据管理3、框架","slug":"接口测试（一）聊聊接口测试","date":"2022-01-20T10:49:36.000Z","categories_index":"测试开发","tags_index":"接口测试","author_index":"Shepard"}]